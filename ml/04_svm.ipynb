{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498c56b1",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n",
    " - Linear classifiers that use the hinge loss function\n",
    " - Trained using the hinge loss and L2 regularization\n",
    " - For hinge loss the observations that fall into the \"flat\" line space do not contribute to the loss (removing them would not change the fit)\n",
    " - Support vectors are defined as training examples that influence the decision boundary\n",
    " - Support vectors are training examples not in the flat part of the loss diagram\n",
    " - Here all incorrectly classified points are support vectors\n",
    " - Also the correctly classified examples but close to the boundary are support vectors\n",
    " - If an example is not a support vector, removing it does not influence the model\n",
    " - The small number of support vectors (i.e. not \"looking\" at all the training points) makes kernel SVMs really fast\n",
    "<img src=\"ml_assets/svm.png\" style=\"width: 300px;\"/>\n",
    "\n",
    " - Fitting a linear model in a transformed space corresponds to fitting a non-linear model in the original space (e.g. feature x -> transformed feature x^2 linearly separable dataset, image shows original vs transformed space)\n",
    "\n",
    "<img src=\"ml_assets/transformed_space.png\" style=\"width: 500px;\"/>\n",
    "\n",
    " - In scikit-learn use LinearSVC for a linear SVM or SVC for a kernerl SVM\n",
    " \n",
    " - Learn more: https://en.wikipedia.org/wiki/Support-vector_machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7408238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Import the necessary modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0228a3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cure = load_breast_cancer()\n",
    "features = pd.DataFrame(scale(cure['data']), columns = cure['feature_names'])\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32803ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.DataFrame(cure['target'], columns=['Type']).replace(0,-1)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ebd54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([target,features],axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607edc15",
   "metadata": {},
   "source": [
    "#### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "429cf52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create arrays for the features and the response variable\n",
    "y = target.values.reshape(-1)\n",
    "X = features.values\n",
    "\n",
    "display(y.shape, X.shape)\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.35,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec14adc",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning gamma and C with GridSearchCV\n",
    "\n",
    " - C controls regularization\n",
    " - kernel is \"rbf\" (radial basis function), but you can use \"linear\" (if you use the latter, there will be no gamma parameter to be set)\n",
    " - gamma controls the smoothness of the curve\n",
    "     - If gamma is too large, the radius of the area of influence of the support vectors only includes the support vector itself and no amount of regularization with C will be able to prevent overfitting\n",
    "     - When gamma is very small, the model is too constrained and cannot capture the complexity or “shape” of the data. The region of influence of any selected support vector would include the whole training set. The resulting model will behave similarly to a linear model with a set of hyperplanes that separate the centers of high density of any pair of two classes\n",
    "\n",
    "<img src=\"ml_assets/gamma.png\" style=\"width: 500px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37611501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'C': 10, 'gamma': 0.01}\n",
      "Best CV accuracy 0.9701592002961867\n",
      "Test accuracy of best grid search hypers: 0.985\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an RBF SVM\n",
    "svm = SVC()\n",
    "\n",
    "# Instantiate the GridSearchCV object and run the search\n",
    "parameters = {'C':[0.1, 1, 10], 'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1]}\n",
    "searcher = GridSearchCV(svm, parameters)\n",
    "searcher.fit(X_train, y_train)\n",
    "\n",
    "# Report the best parameters and the corresponding score\n",
    "print(\"Best CV params\", searcher.best_params_)\n",
    "print(\"Best CV accuracy\", searcher.best_score_)\n",
    "\n",
    "# Report the test accuracy using these best parameters\n",
    "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e56223",
   "metadata": {},
   "source": [
    "#### Stochastic gradient descent\n",
    "\n",
    " - With SGDC you can select the loss method to be either \"logistic\" or \"hinge\"\n",
    " - Scales well with large datasets\n",
    " - The regularization parameter is called alpha and it behaves as the inverse of \"C\" in SVC or Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba073628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV params {'alpha': 0.01, 'loss': 'log', 'penalty': 'l2'}\n",
      "Best CV accuracy 0.9701201201201203\n",
      "Test accuracy of best grid search hypers: 0.99\n"
     ]
    }
   ],
   "source": [
    "# We set random_state=0 for reproducibility \n",
    "linear_classifier = SGDClassifier(random_state=0)\n",
    "\n",
    "# Instantiate the GridSearchCV object and run the search\n",
    "parameters = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \n",
    "             'loss':['hinge', 'log'], 'penalty':['l1','l2']}\n",
    "\n",
    "searcher = GridSearchCV(linear_classifier, parameters, cv=10)\n",
    "\n",
    "searcher.fit(X_train, y_train)\n",
    "\n",
    "# Report the best parameters and the corresponding score\n",
    "print(\"Best CV params\", searcher.best_params_)\n",
    "print(\"Best CV accuracy\", searcher.best_score_)\n",
    "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770fc23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
