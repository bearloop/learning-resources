{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e894527",
   "metadata": {},
   "source": [
    "### AWS Boto3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372707b8",
   "metadata": {},
   "source": [
    "#### Boto3\n",
    "\n",
    " - A library to interact with AWS services\n",
    " - At the very minimum you must pass the service (e.g. s3), region name, and AWS credentials\n",
    "\n",
    "#### IAM\n",
    " - To create a key and secret for boto3 you need to use the Identity Access Management service\n",
    " - Create IAM (sub-)users to control access to services in the AWS account\n",
    " - Credentials or key id and secret combo are what authenticate IAM users\n",
    " - In the AWS console, type IAM to find the services section -> at the IAM screen -> Users -> Add User\n",
    " - Enter a \"user name\" and select \"programmatic access\"\n",
    " - Select \"attach existing policies directly\", search for the proper polcies to add\n",
    " - Create the user and save their credentials\n",
    " \n",
    "#### Create s3 and list its buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35427e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the boto3 client for interacting with S3\n",
    "s3 = boto3.client('s3', region_name='us-east-1', \n",
    "                        # Set up AWS credentials \n",
    "                        aws_access_key_id=AWS_KEY_ID, \n",
    "                         aws_secret_access_key=AWS_SECRET)\n",
    "# List the buckets\n",
    "buckets = s3.list_buckets()\n",
    "\n",
    "# Print the buckets\n",
    "print(buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee9bd8",
   "metadata": {},
   "source": [
    "#### Create sns and list its topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f515a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the boto3 client for interacting with SNS\n",
    "sns = boto3.client('sns', region_name='us-east-1', \n",
    "                         aws_access_key_id=AWS_KEY_ID, \n",
    "                         aws_secret_access_key=AWS_SECRET)\n",
    "\n",
    "# List SNS topics\n",
    "topics = sns.list_topics()\n",
    "\n",
    "# Print out the list of SNS topics\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a2960",
   "metadata": {},
   "source": [
    "#### Boto operations on s3\n",
    "\n",
    " - Instatiate client connection to s3\n",
    " - Create three new buckets\n",
    " - List buckets\n",
    " - Print response\n",
    " - Delete one bucket\n",
    " - List and print again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Create boto3 client to S3\n",
    "s3 = boto3.client('s3', region_name='us-east-1', \n",
    "                         aws_access_key_id=AWS_KEY_ID, \n",
    "                         aws_secret_access_key=AWS_SECRET)\n",
    "\n",
    "# Create the buckets\n",
    "response_staging = s3.create_bucket(Bucket='gim-staging')\n",
    "response_processed = s3.create_bucket(Bucket='gim-processed')\n",
    "response_test = s3.create_bucket(Bucket='gim-test')\n",
    "\n",
    "# Print out the response\n",
    "print(response_staging)\n",
    "\n",
    "# Get the list_buckets response\n",
    "response = s3.list_buckets()\n",
    "\n",
    "# Iterate over Buckets from .list_buckets() response\n",
    "for bucket in response['Buckets']:\n",
    "  \n",
    "    # Print the Name for each bucket\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the gim-test bucket\n",
    "s3.delete_bucket(Bucket='gim-test')\n",
    "\n",
    "# Get the list_buckets response\n",
    "response = s3.list_buckets()\n",
    "\n",
    "# Print each Buckets Name\n",
    "for bucket in response['Buckets']:\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e09500",
   "metadata": {},
   "source": [
    "#### Delete multiple s3 buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a4345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list_buckets response\n",
    "response = s3.list_buckets()\n",
    "\n",
    "# Delete all the buckets with 'gim', create replacements.\n",
    "for bucket in response['Buckets']:\n",
    "    if 'gim' in bucket['Name']:\n",
    "        s3.delete_bucket(Bucket=bucket['Name'])\n",
    "    \n",
    "s3.create_bucket(Bucket='gid-staging')\n",
    "s3.create_bucket(Bucket='gid-processed')\n",
    "  \n",
    "# Print bucket listing after deletion\n",
    "response = s3.list_buckets()\n",
    "for bucket in response['Buckets']:\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e097f",
   "metadata": {},
   "source": [
    "#### S3 buckets vs objects\n",
    "\n",
    " - Similar relationship as folders and files in a file management system\n",
    "![image](assets/boto3/bucket_vs_object.png)\n",
    "\n",
    "#### Uploading objects\n",
    " - Use **upload_file()** method\n",
    " - the filename parameter is the local file path\n",
    " - the Bucket parameter takes the name of the bucket we're uploading to\n",
    " - the key parameter is what we name the object in s3\n",
    " - the method does not return anything, if there is an error it will throw an exception\n",
    "\n",
    "#### Listing objects\n",
    " - the **list_objects()** method will return up to 1000 objects if there are that many available in the bucket\n",
    " - use the prefix argument to limit the response to those objects whose name includes the prefix\n",
    "\n",
    "#### Viewing a single object\n",
    " - use the **head_object()** method passing the bucket's name and object's key\n",
    "\n",
    "#### Downloading a file\n",
    " - use the **download_file()** method to download a file specifying the bucket and key of the object you want to download\n",
    "\n",
    "#### Delete an object\n",
    " - use the **delete_object()** method to delete the object in the bucket passing the bucket and key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac38c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload final_report.csv to gid-staging\n",
    "s3.upload_file(Bucket='gid-staging',\n",
    "              # Set filename and key\n",
    "               Filename='final_report.csv', \n",
    "               Key='2019/final_report_01_01.csv')\n",
    "\n",
    "# Get object metadata and print it\n",
    "response = s3.head_object(Bucket='gid-staging', \n",
    "                       Key='2019/final_report_01_01.csv')\n",
    "\n",
    "# Print the size of the uploaded object\n",
    "print(response['ContentLength'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b4a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List only objects that start with '2018/final_'\n",
    "response = s3.list_objects(Bucket='gid-staging', \n",
    "                           Prefix='2018/final_')\n",
    "\n",
    "# Iterate over the objects\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        # Delete the object\n",
    "        s3.delete_object(Bucket='gid-staging', Key=obj['Key'])\n",
    "\n",
    "# Print the remaining objects in the bucket\n",
    "response = s3.list_objects(Bucket='gid-staging')\n",
    "\n",
    "for obj in response['Contents']:\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9e3c2",
   "metadata": {},
   "source": [
    "#### AWS permissions system\n",
    " - 1. Attaching IAM policies to a user to give access permissions. Applies to all AWS services\n",
    " - 2. Bucket policies give control to a bucket and an object within it\n",
    " - 3. ACL or Access Control Lists let us set permissions on specific objects within a bucket\n",
    " - 4. Presigned URLs let us provide temporary access to an object\n",
    "\n",
    "IAM and bucket policies are used in multi-user environments\n",
    "\n",
    "#### ACLs\n",
    " - Are entities attached to a bucket in s3\n",
    " - Can be private or public-read\n",
    " - Private by default\n",
    " - Set a bucket on \"public read\" with **s3.put_object_acl(Bucket='bucket-name',Key='file.type',ACL='public-read')**\n",
    " - Or on upload with **s3.upload_file(Bucket='bucket-name', Filename='file.type', Key='file.type', ExtraArgs={'ACL':'public-read'})**\n",
    "\n",
    "#### Accessing public object\n",
    " - Use the following http format https://{bucket}.s3.amazonaws.com/{key}\n",
    " - For instance, \"https://{}.s3.amazonaws.com/{}\".format( \"gid-requests\", \"2019/potholes.csv\")\n",
    " - Common pandas read method df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a652909",
   "metadata": {},
   "source": [
    "#### How access is decided\n",
    "![image](assets/boto3/how_access_1.png)\n",
    "![image](assets/boto3/how_access_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15abe3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the final_report.csv to gid-staging bucket\n",
    "s3.upload_file(\n",
    "  # Complete the filename\n",
    "  Filename='./final_report.csv', \n",
    "  # Set the key and bucket\n",
    "  Key='2019/final_report_2019_02_20.csv', \n",
    "  Bucket='gid-staging',\n",
    "  # During upload, set ACL to public-read\n",
    "  ExtraArgs = {\n",
    "    'ACL': 'public-read'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15842bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List only objects that start with '2019/final_'\n",
    "response = s3.list_objects(Bucket='gid-staging', Prefix='2019/final_')\n",
    "\n",
    "# Iterate over the objects\n",
    "for obj in response['Contents']:\n",
    "  \n",
    "    # Give each object ACL of public-read\n",
    "    s3.put_object_acl(Bucket='gid-staging', \n",
    "                      Key=obj['Key'], \n",
    "                      ACL='public-read')\n",
    "    \n",
    "    # Print the Public Object URL for each object\n",
    "    print(\"https://{}.s3.amazonaws.com/{}\".format('gid-staging', obj['Key']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef6aea",
   "metadata": {},
   "source": [
    "#### Reading private files\n",
    "\n",
    "To read private s3 files\n",
    " - either use boto3 client download_file() method to download the file and read from disk with pandas or other method\n",
    " - or use the get_object() method whose obj['Body'] should then be passed to pandas\n",
    " - or use pre-signed urls that are active for a pre-determined amount of time\n",
    "   - s3.generate_presigned_url(  ClientMethod='get_object',  ExpiresIn=3600,  Params={'Bucket': 'gid-requests','Key': 'potholes.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate presigned_url for the uploaded object\n",
    "share_url = s3.generate_presigned_url(\n",
    "  # Specify allowable operations\n",
    "  ClientMethod='get_object',\n",
    "  # Set the expiration time\n",
    "  ExpiresIn=3600,\n",
    "  # Set bucket and shareable object's name\n",
    "  Params={'Bucket': 'gid-staging','Key': 'final_report.csv'}\n",
    ")\n",
    "\n",
    "# Print out the presigned URL\n",
    "print(share_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list =  [ ] \n",
    "\n",
    "for file in response['Contents']:\n",
    "    # For each file in response load the object from S3\n",
    "    obj = s3.get_object(Bucket='gid-requests', Key=file['Key'])\n",
    "    # Load the object's StreamingBody with pandas\n",
    "    obj_df = pd.read_csv(obj['Body'])\n",
    "    # Append the resulting DataFrame to list\n",
    "    df_list.append(obj_df)\n",
    "\n",
    "# Concat all the DataFrames with pandas\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "# Preview the resulting DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d7238",
   "metadata": {},
   "source": [
    "#### Pandas to html and s3 upload\n",
    "\n",
    "Some usefule media types\n",
    " - application/json\n",
    " - image/png\n",
    " - application/pdf\n",
    " - text/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6964542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an HTML table with no border and selected columns\n",
    "services_df.to_html('./services_no_border.html',\n",
    "           # Keep specific columns only\n",
    "           columns=['service_name', 'link'],\n",
    "           # Set border\n",
    "           border=0)\n",
    "\n",
    "# Generate an html table with border and all columns.\n",
    "services_df.to_html('./services_border_all_columns.html', \n",
    "           border=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3340f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the lines.html file to S3\n",
    "s3.upload_file(Filename='lines.html', \n",
    "               # Set the bucket name\n",
    "               Bucket='datacamp-public', Key='index.html',\n",
    "               # Configure uploaded file\n",
    "               ExtraArgs = {\n",
    "                 # Set proper content type\n",
    "                 'ContentType':'text/html',\n",
    "                 # Set proper ACL\n",
    "                 'ACL': 'public-read'})\n",
    "\n",
    "# Print the S3 Public Object URL for the new file.\n",
    "# https://datacamp-website.s3.amazonaws.com/table.html\n",
    "print(\"http://{}.s3.amazonaws.com/{}\".format('datacamp-public', 'index.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe8fdf",
   "metadata": {},
   "source": [
    "#### Mini project to read data and upload as html to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8597d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine daily requests for February\n",
    "\n",
    "\n",
    "df_list = [] \n",
    "\n",
    "# Load each object from s3\n",
    "for file in request_files:\n",
    "    s3_day_reqs = s3.get_object(Bucket='gid-requests', \n",
    "                                Key=file['Key'])\n",
    "    # Read the DataFrame into pandas, append it to the list\n",
    "    day_reqs = pd.read_csv(s3_day_reqs['Body'])\n",
    "    df_list.append(day_reqs)\n",
    "\n",
    "# Concatenate all the DataFrames in the list\n",
    "all_reqs = pd.concat(df_list)\n",
    "\n",
    "# Preview the DataFrame\n",
    "all_reqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1da9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload aggregated reports for February\n",
    "\n",
    "# Write agg_df to a CSV and HTML file with no border\n",
    "agg_df.to_csv('./feb_final_report.csv')\n",
    "agg_df.to_html('./feb_final_report.html', border=0)\n",
    "\n",
    "# Upload the generated CSV to the gid-reports bucket\n",
    "s3.upload_file(Filename='./feb_final_report.csv', \n",
    "\tKey='2019/feb/final_report.html', Bucket='gid-reports',\n",
    "    ExtraArgs = {'ACL': 'public-read'})\n",
    "\n",
    "# Upload the generated HTML to the gid-reports bucket\n",
    "s3.upload_file(Filename='./feb_final_report.html', \n",
    "\tKey='2019/feb/final_report.html', Bucket='gid-reports',\n",
    "    ExtraArgs = {'ContentType': 'text/html', \n",
    "                 'ACL': 'public-read'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3cde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update index to include February\n",
    "\n",
    "# List the gid-reports bucket objects starting with 2019/\n",
    "objects_list = s3.list_objects(Bucket='gid-reports', Prefix='2019/')\n",
    "\n",
    "# Convert the response contents to DataFrame\n",
    "objects_df = pd.DataFrame(objects_list['Contents'])\n",
    "\n",
    "# Create a column \"Link\" that contains Public Object URL\n",
    "base_url = \"http://gid-reports.s3.amazonaws.com/\"\n",
    "objects_df['Link'] = base_url + objects_df['Key']\n",
    "\n",
    "# Preview the resulting DataFrame\n",
    "objects_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78648603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the new index\n",
    "\n",
    "# Write objects_df to an HTML file\n",
    "objects_df.to_html('report_listing.html',\n",
    "    # Set clickable links\n",
    "    render_links=True,\n",
    "    # Isolate the columns\n",
    "    columns=['Link', 'LastModified', 'Size'])\n",
    "\n",
    "# Overwrite index.html key by uploading the new file\n",
    "s3.upload_file(\n",
    "  Filename='./report_listing.html', Key='index.html', \n",
    "  Bucket='gid-reports',\n",
    "  ExtraArgs = {\n",
    "    'ContentType': 'text/html', \n",
    "    'ACL': 'public-read'\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4214e42",
   "metadata": {},
   "source": [
    "![image](assets/boto3/result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10f648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
